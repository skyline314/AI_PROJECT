{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a038a60a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memuat model...\n",
      "Model berhasil dimuat.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kenny\\AppData\\Local\\Temp\\ipykernel_25112\\3536868365.py:31: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(MODEL_PATH, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Webcam aktif. Tekan 'q' untuk keluar.\n",
      "Menutup aplikasi.\n"
     ]
    }
   ],
   "source": [
    "# realtime_detector.py\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "\n",
    "# --- KONFIGURASI ---\n",
    "# Path ke model yang sudah disimpan\n",
    "MODEL_PATH = \"model/yawn_detector_notebook.pth\" \n",
    "\n",
    "# Nama kelas harus sesuai dengan urutan saat training\n",
    "CLASS_NAMES = ['no_yawn', 'yawn']\n",
    "# --------------------\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Fungsi utama untuk menjalankan detektor real-time.\"\"\"\n",
    "    \n",
    "    # 1. Muat Model\n",
    "    print(\"Memuat model...\")\n",
    "    device = torch.device(\"cpu\")\n",
    "    \n",
    "    # Definisikan arsitektur model (harus sama persis)\n",
    "    model = models.mobilenet_v2()\n",
    "    num_ftrs = model.classifier[1].in_features\n",
    "    model.classifier[1] = nn.Linear(num_ftrs, len(CLASS_NAMES))\n",
    "    \n",
    "    # Muat bobot yang sudah dilatih\n",
    "    model.load_state_dict(torch.load(MODEL_PATH, map_location=device))\n",
    "    model.to(device)\n",
    "    model.eval() # Set ke mode evaluasi\n",
    "    print(\"Model berhasil dimuat.\")\n",
    "    \n",
    "    # 2. Definisikan transformasi gambar (harus sama dengan validasi)\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    # 3. Inisialisasi Webcam\n",
    "    cap = cv2.VideoCapture(0) # 0 adalah ID untuk webcam default\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Tidak bisa membuka webcam.\")\n",
    "        return\n",
    "        \n",
    "    print(\"\\nWebcam aktif. Tekan 'q' untuk keluar.\")\n",
    "    \n",
    "    # 4. Loop Real-time\n",
    "    while True:\n",
    "        # Baca satu frame dari webcam\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Gagal membaca frame. Keluar...\")\n",
    "            break\n",
    "            \n",
    "        # Balik frame secara horizontal agar seperti cermin\n",
    "        frame = cv2.flip(frame, 1)\n",
    "\n",
    "        # Proses frame untuk prediksi\n",
    "        # Konversi frame OpenCV (BGR) ke PIL Image (RGB)\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        pil_image = Image.fromarray(rgb_frame)\n",
    "        \n",
    "        # Terapkan transformasi dan buat batch\n",
    "        input_tensor = transform(pil_image).unsqueeze(0).to(device)\n",
    "        \n",
    "        # Lakukan prediksi\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_tensor)\n",
    "            probabilities = torch.nn.functional.softmax(outputs[0], dim=0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "            predicted_class = CLASS_NAMES[preds.item()]\n",
    "            confidence = probabilities[preds.item()].item()\n",
    "            \n",
    "        # Tentukan warna teks berdasarkan prediksi\n",
    "        if predicted_class == 'yawn':\n",
    "            text_color = (0, 0, 255) # Merah\n",
    "        else:\n",
    "            text_color = (0, 255, 0) # Hijau\n",
    "            \n",
    "        # Tampilkan hasil prediksi pada frame\n",
    "        text = f\"Prediksi: {predicted_class} ({confidence:.2%})\"\n",
    "        cv2.putText(frame, text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.9, text_color, 2)\n",
    "        \n",
    "        # Tampilkan frame di jendela\n",
    "        cv2.imshow('Real-time Yawn Detector', frame)\n",
    "        \n",
    "        # Cek jika tombol 'q' ditekan untuk keluar\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "            \n",
    "    # 5. Bersihkan\n",
    "    print(\"Menutup aplikasi.\")\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yawn_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
